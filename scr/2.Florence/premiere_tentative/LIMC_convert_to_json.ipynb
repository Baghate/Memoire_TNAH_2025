{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rV2KlOjuhki6"},"outputs":[],"source":["import re\n","import os\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J52IyrKRhkjA"},"outputs":[],"source":["def open_txt(file):\n","    with open(file,\"r\") as ocr:\n","        text = ocr.read()\n","\n","    return text"]},{"cell_type":"code","source":["def catalog_content(catalog):\n","    # Régex de récupération des entrées du catalogue\n","    pattern = r'^(\\d+)\\.*?\\s*(.*?)\\n(?=\\d+\\.|\\Z)'\n","\n","    # Extraction des entrées : findall renvoie un tuple avec chaque groupe de capture\n","    entries = re.findall(pattern, catalog, re.MULTILINE | re.DOTALL)\n","\n","    # Liste de sortie\n","    catalog_data = []\n","\n","    # Traitement de chaque entrée\n","    for entry in entries:\n","        number, description = entry\n","\n","        # Déterminer le type d'entrée\n","        if description.startswith('.*'):\n","            entry_type = \"planche\"\n","        elif description.startswith('.\"'):\n","            entry_type = \"sketch\"\n","        else:\n","            entry_type = \"no_planche\"\n","\n","        # Ajouter les données formatées à la liste\n","        catalog_data.append({\n","            \"number\": number.strip(),\n","            \"type\": entry_type,\n","            \"description\": description.strip()\n","        })\n","\n","    return catalog_data\n"],"metadata":{"id":"IgiVwDf3ipON"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAgXqL8MhkjB"},"outputs":[],"source":["def get_limc_structure(file):\n","    text = open_txt(file)\n","\n","    # Extraire la première ligne (nom de la notice)\n","    first_line_match = re.match(r'^([A-Z\\s-]+)', text)\n","    notice_name = first_line_match.group(0).strip() if first_line_match else \"Unknown\"\n","\n","    # Introduction (avant \"LITERARY SOURCES\")\n","    intro_match = re.search(r'^(.*?)\\nLITERARY SOURCES', text, re.DOTALL)\n","    introduction = intro_match.group(1).strip() if intro_match else \"Missing introduction\"\n","\n","    # Literary source (entre \"LITERARY SOURCES\" et \"BIBLIOGRAPHY\")\n","    literary_source_match = re.search(r'LITERARY SOURCES\\s*(.*?)\\nBIBLIOGRAPHY', text, re.DOTALL)\n","    literary_source = literary_source_match.group(1).strip() if literary_source_match else \"Missing literary source\"\n","\n","    # Bibliography (entre \"BIBLIOGRAPHY\" et \"CATALOGUE\")\n","    bibliography_match = re.search(r'BIBLIOGRAPHY\\s*.*?:\\s*(.*?)(?=\\nCATALOGUE)', text, re.DOTALL)\n","    bibliography = bibliography_match.group(1).strip() if bibliography_match else \"Missing bibliography\"\n","\n","    # Catalog (entre \"CATALOGUE\" et \"COMMENTARY\")\n","    catalog_match = re.search(r'CATALOGUE\\s*(.*?)(?=\\nCOMMENTARY)', text, re.DOTALL)\n","    catalog = catalog_match.group(1).strip() if catalog_match else \"Missing catalog\"\n","\n","    # Extraire les données du catalogue (exemple d'extraction spécifique)\n","    catalog_data = catalog_content(catalog) if 'catalog_content' in globals() else catalog\n","\n","    return notice_name, introduction, literary_source, bibliography, catalog_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mVKkzvGhkjD"},"outputs":[],"source":["def create_json(file, output_folder):\n","\n","    notice_name, introduction, literary_source, bibliography, catalog_data = get_limc_structure(file)\n","\n","\n","    # Construire la structure JSON\n","    notice = {\n","        notice_name: {\n","            \"Introduction\": introduction,\n","            \"Literary source\": literary_source,\n","            \"Bibliography\": bibliography,\n","            \"Catalog\": catalog_data,\n","        }\n","    }\n","\n","\n","    json_filename = os.path.basename(file).replace('.txt', '.json')\n","    output_path = os.path.join(output_folder, json_filename)\n","\n","\n","    os.makedirs(output_folder, exist_ok=True)\n","    with open(output_path, 'w', encoding='utf-8') as result:\n","        json.dump(notice, result, ensure_ascii=False, indent=4)\n","\n","    print(f\"{json_filename} saved in {output_folder}\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2Lw7QTucZA7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734704571507,"user_tz":-60,"elapsed":19570,"user":{"displayName":"Chaouabti Chaouabti","userId":"12266396455066797570"}},"outputId":"5a3eb3b7-5274-472f-8aee-cbc98c2cfd90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqd121URhkjE"},"outputs":[],"source":["file = '/content/drive/MyDrive/Hackhaton_Hercule/data/Herakles_cleaned.txt'\n","output_folder = '/content/drive/MyDrive/Hackhaton_Hercule/output'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxLHRv5UhkjE","executionInfo":{"status":"ok","timestamp":1734694825086,"user_tz":-60,"elapsed":172,"user":{"displayName":"Maxime Griveau","userId":"09295367027132223123"}},"outputId":"5ccc8335-75a9-4f51-8c81-e96c1347d945"},"outputs":[{"output_type":"stream","name":"stdout","text":["test\n","Herakles_cleaned.json saved in /content/drive/MyDrive/Hackhaton_Hercule/output\n"]}],"source":["create_json(file, output_folder)"]}],"metadata":{"kernelspec":{"display_name":"Arts_Deco","language":"python","name":"arts_deco"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}