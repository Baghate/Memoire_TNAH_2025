{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdda0f4b",
   "metadata": {},
   "source": [
    "# Code pour nettoyer et manipuler les csv d'export des corpus de Th√©r√®se Bonney et de l'Exposition Universelle de 1937 en vue du scraping üßπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da36089",
   "metadata": {},
   "source": [
    "*Les exports en csv pr√©sentaient des irr√©gularit√©s et des coquilles emp√™chant l'automatisation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086c50b",
   "metadata": {},
   "source": [
    "## Environnement üåê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be2e12",
   "metadata": {},
   "source": [
    "### Import des librairies üìñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "02380e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "from contextlib import redirect_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688a6a9",
   "metadata": {},
   "source": [
    "## Fonctions ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a268733",
   "metadata": {},
   "source": [
    "### Fonction pour le csv \"Expo_1937_photos.csv\" üèóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36409458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_expo(input_file_expo):\n",
    "    remove_first_line_csv(input_file_expo)\n",
    "    bad_lines, parsing_error = detect_bad_lines_expo(input_file_expo)\n",
    "    try:\n",
    "        df = pd.read_csv(input_file_expo)\n",
    "    except Exception as e:\n",
    "        print(\"Erreur de parsing :\", e)\n",
    "    clean_url(input_file_expo)\n",
    "    clean_quotes_and_expressions(input_file_expo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf5210",
   "metadata": {},
   "source": [
    "### Suppression premi√®re ligne du csv ü•á\n",
    "\n",
    "*La premi√®re ligne du csv comprend une seule colonne avec \"rapport_33396\" ce qui emp√™che pandas de lire correctement l'en-t√™te*\n",
    "\n",
    "**La fonction doit √™tre comment√©e si on refait une passe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "96938a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_line_csv(filepath):\n",
    "    \"\"\"Supprime la premi√®re ligne d'un fichier CSV (en place).\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d950b",
   "metadata": {},
   "source": [
    "### D√©tecter les lignes fautives d'un csv üìè\n",
    "\n",
    "+ Utilisation de la librairie io et de redirect_stderr pour capturer les lignes fautives du csv ne comportant pas le bon nombre de colonnes\n",
    "\n",
    "*Le besoin s'est fait ressentir de passer par une phase pr√©alable de troubleshooting face √† l'impossibilit√© de lire le csv avec un simple pd.read_csv*\n",
    "\n",
    "Except√© une petite modification d√ª √† un changement dans la syntaxe de pandas dans la version 1.3.0 (concernant le param√®tre \"on_bad_lines\").\n",
    "\n",
    "Les cr√©dits vont √† :\n",
    "\n",
    "¬© vlogize https://www.youtube.com/watch?v=1fdePybJ0yQ\n",
    "CC BY-SA 4.0\n",
    "\n",
    "Based on a Stack Overflow exchange https://stackoverflow.com/users/6238676/prish\n",
    "Also under CC BY-SA 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f72ee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bad_lines_expo(input_file_expo, sep=';', encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    D√©tecte les lignes fautives (mauvais nombre de colonnes) dans un CSV.\n",
    "    Retourne la liste des num√©ros de lignes probl√©matiques.\n",
    "    \"\"\"\n",
    "    # Prepare capture warnings\n",
    "    f = io.StringIO()\n",
    "    parsing_error = None\n",
    "    with redirect_stderr(f):\n",
    "        try:\n",
    "            pd.read_csv(input_file_expo, sep=sep, encoding=encoding, on_bad_lines='warn')\n",
    "        except Exception as e:\n",
    "            parsing_error = str(e)\n",
    "    # Extract warning messages\n",
    "    warning_str = f.getvalue()\n",
    "\n",
    "    # Using Regex to capture line numbers\n",
    "    regex = re.compile(r'line ([0-9]+)')\n",
    "    line_numbers = regex.findall(warning_str)\n",
    "    \n",
    "    return line_numbers, parsing_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f99fc",
   "metadata": {},
   "source": [
    "### Suppression des espaces qui se sont gliss√©s dans l'export üåå\n",
    "\n",
    "*Les adresses des sites des biblioth√®ques sp√©cialis√©es de Paris comportaient un espace entre la fin de l'adresse et le \".fr\" emp√™chant l'automatisation*\n",
    "\n",
    "Cod√© avec Github Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "be60d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(input_file_expo):\n",
    "    \"\"\"\n",
    "    Nettoie les URLs du fichier CSV en supprimant l'espace dans 'paris .fr'.\n",
    "    Modifie le fichier en place.\n",
    "    \"\"\"\n",
    "    import csv\n",
    "\n",
    "    def clean_url(url):\n",
    "        return url.replace(\"paris .fr\", \"paris.fr\")\n",
    "\n",
    "    # Lire tout le contenu et nettoyer\n",
    "    with open(input_file_expo, mode='r', encoding='utf-8') as infile:\n",
    "        rows = []\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            cleaned_row = [clean_url(cell) if \"https://bibliotheques-specialisees.paris\" in cell else cell for cell in row]\n",
    "            rows.append(cleaned_row)\n",
    "\n",
    "    # R√©√©crire le fichier nettoy√©\n",
    "    with open(input_file_expo, mode='w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c27bf7",
   "metadata": {},
   "source": [
    "### Supression des coats et des expressions probl√©matiques üß•\n",
    "\n",
    "Cod√© avec Github Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a0a17c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_quotes_and_expressions(input_file_expo):\n",
    "    \"\"\"\n",
    "    Supprime les guillemets et expressions probl√©matiques dans le fichier CSV.\n",
    "    Modifie le fichier en place.\n",
    "    \"\"\"\n",
    "    with open(input_file_expo, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Suppression des guillemets et expressions sp√©cifiques via des RegEx\n",
    "    content = re.sub(r'\\\"\\\"\\\"', '', content)\n",
    "    content = re.sub(r'\\\"\\\"', '', content)\n",
    "    content = re.sub(r'\\\"', '', content)\n",
    "    content = re.sub(r'\\\"https', 'https', content)\n",
    "    content = re.sub(r'\\\", Th√©r√®se', ', Th√©r√®se', content)\n",
    "    content = re.sub(r'\\\", Paris', ', Paris', content)\n",
    "    content = re.sub(r',\\\" inauguration', ' inauguration', content)\n",
    "    content = re.sub(r',\\\" la brasserie', ' la brasserie', content)\n",
    "    content = re.sub(r', avec Marcel Maillard', ' avec Marcel Maillard', content)\n",
    "    content = re.sub(r', des Gobelins', ' des Gobelins', content)\n",
    "    content = re.sub(r', architectes du', ' architectes du', content)\n",
    "    content = re.sub(r'BHVP, *', 'BHVP;', content)\n",
    "    content = re.sub(r'BHVP;.*', ' BHVP;', content)\n",
    "    content = re.sub(r'\\\"La D√©coratrice\\\"\\\",\\\"', '\\\"La D√©coratrice\\\"', content)\n",
    "    content = re.sub(r' , Paris 1937', ' Paris 1937', content)\n",
    "    content = re.sub(r',', '', content)\n",
    "\n",
    "    with open(input_file_expo, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "    print(\"Les guillemets et expressions probl√©matiques ont √©t√© supprim√©s avec succ√®s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49edab",
   "metadata": {},
   "source": [
    "### Fonction pour le csv \"Corpus_Therese_Bonney_BnF.csv\" üèóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "776647cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_bonney(input_file_bonney):\n",
    "    bad_lines, parsing_error = detect_bad_lines_bonney(input_file_bonney)\n",
    "    try:\n",
    "        df = pd.read_csv(input_file_bonney)\n",
    "    except Exception as e:\n",
    "        print(\"Erreur de parsing :\", e)\n",
    "    clean_quotes_and_expressions_bonney(input_file_bonney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6e6d04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bad_lines_bonney(input_file_bonney, sep=';', encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    D√©tecte les lignes fautives (mauvais nombre de colonnes) dans un CSV.\n",
    "    Retourne la liste des num√©ros de lignes probl√©matiques.\n",
    "    \"\"\"\n",
    "    # Prepare capture warnings\n",
    "    f = io.StringIO()\n",
    "    parsing_error = None\n",
    "    with redirect_stderr(f):\n",
    "        try:\n",
    "            pd.read_csv(input_file_bonney, sep=sep, encoding=encoding, on_bad_lines='warn')\n",
    "        except Exception as e:\n",
    "            parsing_error = str(e)\n",
    "    # Extract warning messages\n",
    "    warning_str = f.getvalue()\n",
    "\n",
    "    # Using Regex to capture line numbers\n",
    "    regex = re.compile(r'line ([0-9]+)')\n",
    "    line_numbers = regex.findall(warning_str)\n",
    "    \n",
    "    return line_numbers, parsing_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5ecf9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_quotes_and_expressions_bonney(input_file_expo):\n",
    "    \"\"\"\n",
    "    Supprime les guillemets et expressions probl√©matiques dans le fichier CSV.\n",
    "    Modifie le fichier en place.\n",
    "    \"\"\"\n",
    "    with open(input_file_expo, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Suppression des guillemets et expressions sp√©cifiques\n",
    "    content = re.sub(r'\\\"\\\"\\\"', '', content)\n",
    "    content = re.sub(r'\\\"\\\"', '', content)\n",
    "    content = re.sub(r'\\\"', '', content)\n",
    "    content = re.sub(r',', '', content)\n",
    "\n",
    "    with open(input_file_expo, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "    print(\"Les guillemets et expressions probl√©matiques ont √©t√© supprim√©s avec succ√®s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2538e",
   "metadata": {},
   "source": [
    "## Processing ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342de40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_expo = \"\"\n",
    "input_file_bonney = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16aad9",
   "metadata": {},
   "source": [
    "### Lancement du traitement pour le csv Exposition Universelle 1937 üåç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_expo(input_file_expo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c545124",
   "metadata": {},
   "source": [
    "**Si la fonction renvoie une \"Erreur de parsing : Error tokenizing data. C error: Expected x fields in line y, saw z\"**\n",
    "\n",
    "Relancer la fonction de cleaning **en commentant la fonction de suppression de la premi√®re ligne**\n",
    "\n",
    "Si le probl√®me persiste :\n",
    "\n",
    "Alors ouvrir le csv dans Libreoffice, enregistrer et le refermer. Cela r√®gle le probl√®me en r√©ecrivant un nombre coh√©rent de colonnes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0260b0",
   "metadata": {},
   "source": [
    "### Lancement du traitement pour le csv Th√©r√®se Bonney üì∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ea743",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_bonney(input_file_bonney)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18998c6b",
   "metadata": {},
   "source": [
    "**Si la fonction renvoie une \"Erreur de parsing : Error tokenizing data. C error: Expected x fields in line y, saw z\"**\n",
    "\n",
    "Relancer la fonction de cleaning \n",
    "\n",
    "Si le probl√®me persiste :\n",
    "\n",
    "Alors ouvrir le csv dans Libreoffice, enregistrer et le refermer. Cela r√®gle le probl√®me en r√©ecrivant un nombre coh√©rent de colonnes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nettoyage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
